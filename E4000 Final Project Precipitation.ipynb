{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e423d23",
   "metadata": {},
   "source": [
    "# Import Data and data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa0044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470a7a99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "precipitation=pd.read_csv('Precip.csv')\n",
    "precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605cbec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessaru libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5346ff4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Precipitation=precipitation.drop('SNOW', axis=1)\n",
    "Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa80411",
   "metadata": {},
   "outputs": [],
   "source": [
    "cormat=Precipitation.corr()\n",
    "round(cormat,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bee414",
   "metadata": {},
   "outputs": [],
   "source": [
    "Precipitation.set_index('DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4283c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make correlation heatmap\n",
    "import seaborn as sns\n",
    "sns.heatmap(Precipitation.corr(),annot=True)\n",
    "plt.title('Feature correlation heatmap')\n",
    "# Set the parameter for the size of the plot we want\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f786e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unit Conversion\n",
    "Precipitation['Humidity']=Precipitation['Humidity'].apply(lambda x: float(x))\n",
    "Precipitation['Humidity'] = Precipitation['Humidity'] * 0.01\n",
    "Precipitation['Humidity'].round(2)\n",
    "Precipitation['Precipitation'] = Precipitation['Precipitation'].apply(lambda x: round(x*25.4,2))\n",
    "Precipitation['TMAX']= Precipitation['TMAX'].apply(lambda x: round((x-32)*(5/9)))\n",
    "Precipitation['TMIN']= Precipitation['TMIN'].apply(lambda x: round((x-32)*(5/9)))\n",
    "Precipitation['TAVG']= Precipitation['TAVG'].apply(lambda x: round((x-32)*(5/9)))\n",
    "Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06363d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Data processing\n",
    "p = Precipitation\n",
    "p1 = p[p.isna().any(axis=1)]\n",
    "p['TMIN'] = p['TMIN'].fillna(17.94)\n",
    "Pfinal=p.loc[~(p['Precipitation']==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15359c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#log transformation\n",
    "Pfinal['Precipitation']=np.log(p['Precipitation'])\n",
    "Pfinal['Humidity']=np.log(p['Humidity'])\n",
    "Pfinal['SLP'] = np.log(p['SLP'])\n",
    "Pfinal['SP'] = np.log(p['SP'])\n",
    "Pfinal['TMAX'] = np.log(p['TMAX'])\n",
    "Pfinal['TMIN'] = np.log(p['TMIN'])\n",
    "Pfinal['TAVG'] = np.log(p['TAVG'])\n",
    "Pfinal['WD'] = np.log(p['WD'])\n",
    "Pfinal['WDF2'] = np.log(p['WDF2'])\n",
    "Pfinal['WS'] = np.log(p['WS'])\n",
    "Pfinal['WSF2'] = np.log(p['WSF2'])\n",
    "Pfinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d5e567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Importing metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c606dfc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"WSF2\", y=\"Precipitation\", data=Pfinal)\n",
    "sns.lmplot(x=\"WSF2\", y=\"Precipitation\", data=Pfinal)\n",
    "sns.lmplot(x=\"Humidity\", y=\"Precipitation\", data=Pfinal)\n",
    "sns.lmplot(x=\"TMIN\", y=\"Precipitation\", data=Pfinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15fb159",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pfinal.set_index('DATE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd40bd1",
   "metadata": {},
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383bf98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define input and output\n",
    "X = Pfinal.loc[:,['LATITUDE','LONGITUDE','Humidity','SLP','SP','TMAX','TAVG','WSF2','WDF2','TMIN','WD','WS']]\n",
    "y = Pfinal.loc[:,'Precipitation']\n",
    "\n",
    "X_train_df, X_test_df, y_train_df, y_test_df = train_test_split(X, y, test_size=0.33, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32414526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "mean, std = X_train_df.mean(), X_train_df.std()\n",
    "\n",
    "X_train_df = (X_train_df - mean)/std\n",
    "X_test_df  = (X_test_df - mean)/std\n",
    "\n",
    "X_train = X_train_df.to_numpy()\n",
    "y_train = y_train_df.to_numpy()\n",
    "X_test = X_test_df.to_numpy()\n",
    "y_test = y_test_df.to_numpy()\n",
    "\n",
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762a3828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created simple reporting function\n",
    "def clf_performance(classifier, model_name):\n",
    "    print(model_name)\n",
    "    print('Best Score: ' + str(classifier.best_score_))\n",
    "    print('Best Parameters: ' + str(classifier.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd51a2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rf = RandomForestRegressor()\n",
    "param_grid =  {'n_estimators': [200,400,600,800,1000], \n",
    "                                  'bootstrap': [True,False],\n",
    "                                  'max_depth': [10,20,30,40],\n",
    "                                  'max_features': ['auto','sqrt'],\n",
    "                                  'min_samples_leaf': [4,8,12,16,20],\n",
    "                                  'min_samples_split': [5,10,15,25]}\n",
    "                                  \n",
    "rf_par = RandomizedSearchCV(estimator=rf, param_distributions = param_grid, n_iter = 10, cv = 200, verbose = 2,random_state = 100)\n",
    "best_rf = rf_par.fit(X_train,y_train)\n",
    "outputrf = best_rf.predict(X_test)\n",
    "clf_performance(best_rf,'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a65eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a6e6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "print('MAE:', mean_absolute_error(y_test, outputrf))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, outputrf)))\n",
    "print('R2_Score:', r2_score(y_test, outputrf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c85af8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 4))\n",
    "plt.scatter(y_test, outputrf,color='paleturquoise', linewidths=2, edgecolors='k')\n",
    "plt.xlabel('True Precipitation') \n",
    "plt.ylabel('Predicted Precipitation') \n",
    "plt.title('Random Forest Regression Prediction Performance') \n",
    "plt.grid()\n",
    "plt.xlim(plt.xlim(0,6))\n",
    "plt.ylim(plt.ylim(0,4))\n",
    "\n",
    "m,b = np.polyfit(y_test,outputrf,1)\n",
    "x = np.arange(y_test.min(),y_test.max(),5.5)\n",
    "plt.plot(x,m*x+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd5158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating time series plot\n",
    "Pfinal_prep = Pfinal.set_index('DATE')\n",
    "Pfinal_prep['Precipitation'].plot(figsize=(12,5),use_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c07c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pfinal_prep['Precipitation'].plot(figsize=(12,5),use_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b0f1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(y_test, label='Expected')\n",
    "pyplot.plot(outputrf, label='Predicted')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b428bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(importance, names):\n",
    "    #Create arrays from feature importance and feature names\n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "\n",
    "    #Create a DataFrame using a Dictionary\n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "\n",
    "    #Sort the DataFrame in order decreasing feature importance\n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "\n",
    "    #Define size of bar plot\n",
    "    plt.figure(figsize=(10,8))\n",
    "    #Plot Searborn bar chart\n",
    "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
    "    #Add chart labels\n",
    "    plt.title('FEATURE IMPORTANCE')\n",
    "    plt.xlabel('FEATURE IMPORTANCE')\n",
    "    plt.ylabel('FEATURE NAMES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1abbcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(rf.feature_importances_, X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fddf07",
   "metadata": {},
   "source": [
    "# XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107e4fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xgb = {'objective': 'reg:squarederror',\n",
    "              #'base_score': 0.5,     # chosen as median of validation set\n",
    "              'n_estimators': 800,  # number of trees to use\n",
    "              #'learning_rate': 0.01, \n",
    "              'max_depth': 10,       # how many levels are in each tree\n",
    "              #'subsample': 1,\n",
    "              #'colsample_bytree': 0.8,\n",
    "              # REGULARIZATION  alpha (L2) and lambda (L1)\n",
    "              'reg_alpha': 0,\n",
    "              'reg_lambda': 1,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2139bcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(**params_xgb)\n",
    "model.fit(X_train, y_train)\n",
    "rf_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ace5dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "print('MAE:', mean_absolute_error(y_test, rf_pred))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, rf_pred)))\n",
    "print('R2_Score:', r2_score(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170f4fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(importance, names):\n",
    "    #Create arrays from feature importance and feature names\n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "\n",
    "    #Create a DataFrame using a Dictionary\n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "\n",
    "    #Sort the DataFrame in order decreasing feature importance\n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "\n",
    "    #Define size of bar plot\n",
    "    plt.figure(figsize=(10,8))\n",
    "    #Plot Searborn bar chart\n",
    "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
    "    #Add chart labels\n",
    "    plt.title('FEATURE IMPORTANCE')\n",
    "    plt.xlabel('FEATURE IMPORTANCE')\n",
    "    plt.ylabel('FEATURE NAMES')\n",
    "plot_feature_importance(model.feature_importances_, X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92187cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 4))\n",
    "plt.scatter(y_test, rf_pred,color='paleturquoise', linewidths=2, edgecolors='k')\n",
    "plt.xlabel('True Precipitation') \n",
    "plt.ylabel('Predicted Precipitation') \n",
    "plt.title('XGBoost Prediction Performance') \n",
    "plt.grid()\n",
    "plt.xlim(plt.xlim(0,6))\n",
    "plt.ylim(plt.ylim(0,4))\n",
    "\n",
    "m,b = np.polyfit(y_test,rf_pred,1)\n",
    "x = np.arange(y_test.min(),y_test.max(),5.5)\n",
    "plt.plot(x,m*x+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb82545",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pfinal_prep = Pfinal.set_index('DATE')\n",
    "Pfinal_prep['Precipitation'].plot(figsize=(12,5),use_index = True)\n",
    "from matplotlib import pyplot\n",
    "pyplot.plot(y_test, label='Expected')\n",
    "pyplot.plot(rf_pred, label='Predicted')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e8456c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
